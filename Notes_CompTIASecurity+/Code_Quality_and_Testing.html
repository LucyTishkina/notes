<!doctype html><html>
<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <title>Code Quality and Testing</title>
  <meta name="generator" content="CherryTree">
  <link rel="stylesheet" href="res/styles3.css" type="text/css" />
  
    <script type="text/javascript">
        function in_frame () { try { return window.self !== window.top; } catch (e) { return true; } }
        if (!in_frame()) {
            var page = location.pathname.substring(location.pathname.lastIndexOf("/") + 1);
            window.location = 'index.html#' + page;
        }
    </script>
</head>
<body><div class="page"><h1 class="title">Code Quality and Testing</h1><br/>Static code analyzers<br />- Static Application Security Testing (SAST)<br />   → help to identify security flows<br />- many security vulnerabilities found easily<br />   → buffer overflows, database injections, etc.<br />- not everything can be identified through analysis<br />   → authentication security, insecure cryptography, etc.<br />   → don't rely on automation for everything<br />- still have to verify each finding<br />   → false positives are an issue<br /><br />Dynamic analysis (fuzzing)<br />- send random input to an application<br />   → fault-injecting, robustness testing, syntax testing, negative testing<br />- looking for something out of the ordinary<br />   → application crash, server error, exception<br />- 1988 class project at the University of Wisconsin<br />   → “Operating System Utility Program Reliability”<br />   → Professor Barton Miller<br />   → The Fuzz Generator<br /><br />Fuzzing engines and frameworks<br />- many different fuzzing options<br />   → platform specific, language specific, etc.<br />- very time and processor resource heavy<br />   → many, many different iterations to try<br />   → many fuzzing engines use high-probability tests<br />- Carnegie Mellon Computer Emergency Response Team (CERT)<br />   → CERT Basic Fuzzing Framework (BFF)<br /><br />Stress testing<br />- the software works with one user<br />   → what about 1000 users?<br />- inadvertent results can occur at load<br />   → unintended error messages<br />   → application details and versions displayed to the user<br />   → kernel and memory dumps<br />- extensive automation options<br />   → automate individual workstations<br />   → simulate large workstation loads<br />   → extensive reporting<br /><br />Sandboxing<br />- test is  a bit different than the developer's sandbox<br />   → a different sandbox at a different playground<br />- test environment looks and works exactly like production<br />   → no production systems are used<br />   → no production data is used<br />- QA can fuzz, overload, and try to break the sandboxed environment<br />   → you can't hurt anything in the sandbox<br /><br />Model verification<br />- verification and validation (V&amp;V)<br />   → you started development with a set of requirements<br />- verification<br />   → does the software work properly?<br />   → are there any bugs to address?<br />   → are we building the product right?<br />- validation<br />   → did you meet the high level reqs?<br />   → are building the right product<br /><br />Compiled vs runtime code<br />- compiled code<br />   → you don't see the source code<br />   → the application is an executable compiled from the source<br />   → the compiled code is specific to an OS and CPU<br />   → logical bugs can be identified at compile time<br />- runtime code<br />   → source code is usually viewable<br />   → the  code instructions execute when the application is run<br />   → no opportunity to find compile-time errors, so errors are detected during or after execution<br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /></div></body></html>